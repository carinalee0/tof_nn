{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib graphs will be included in your notebook, next to the code:\n",
    "%matplotlib inline\n",
    "\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#add PyTorch and TorchVision (used for cropping etc.)\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 11, 1000)\n"
     ]
    }
   ],
   "source": [
    "normalized_data_path = \"//home//jovyan//simion_files//TOF_ML//simulations//TOF_data//08082024_normalized\"\n",
    "normalized_data_raw = pd.read_pickle(normalized_data_path)\n",
    "# <KeysViewHDF5 ['final_azimuth', 'final_elevation', 'final_ke', 'initial_azimuth', 'initial_elevation', 'initial_ke', 'ion_number', 'tof', 'x', 'y', 'z']>\n",
    "print(normalized_data_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([576000, 11])\n"
     ]
    }
   ],
   "source": [
    "# Flatten data\n",
    "normalized_data_tensor = torch.tensor(normalized_data_raw)\n",
    "normalized_data_tensor = normalized_data_tensor.permute(0, 2, 1).flatten(start_dim=0, end_dim=1)\n",
    "print(normalized_data_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redirect data so that PyTorch is not working with directly\n",
    "\n",
    "# Define class. \n",
    "class SIMdataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "labels = normalized_data_tensor[:,7]\n",
    "data = normalized_data_tensor[:,[x for x in range(0,11) if x !=7]] # All data that is excluding the labels.\n",
    "\n",
    "# Split training and test data, set to 50/50 split\n",
    "data_train, data_test, label_train, label_test = train_test_split(\n",
    "    data, labels, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "# Dataloader\n",
    "train_data = SIMdataset(data_train, label_train)\n",
    "test_data = SIMdataset(data_test, label_test)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, num_workers=num_cores)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, num_workers=num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for the NN\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        hidden_size = 20\n",
    "        \n",
    "        self.linear1 = nn.Linear(10, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #propagate through model\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, train_loader, optimizer):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    \n",
    "    #set network to training mode\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        #iterate through data batches\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            #reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #evaluate network with data\n",
    "            output = model(data)\n",
    "\n",
    "            #compute loss and derivative\n",
    "            loss = nn.MSELoss(output, target) # target is label\n",
    "            loss.backward()\n",
    "\n",
    "            #step optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            torch.save(model.state_dict(), cwd + '/results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), cwd + '/results/optimizer.pth')\n",
    "        \n",
    "    return train_losses, train_counter\n",
    "\n",
    "def test_model(model,loader):\n",
    "    test_losses = []\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            output = model(data)\n",
    "            test_loss += nn.MSELoss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
